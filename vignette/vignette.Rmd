---
title: "Rifi comparative data"

author: "Loubna Youssar"

date: "`r Sys.Date()`"
output:
  BiocStyle::html_document:
    toc: true
    toc_float: true
    number_sections: false
vignette: >
  %\VignetteIndexEntry{Rifi}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
  

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      message = TRUE,
                      warning = TRUE)
```

## 0. Installation

Required dependencies are cited on README, please make sure they are properly
installed (README).
All functions should be located on the same folder and add them to your 
path directory.

## I. Introduction

Rifi comparative data is a successor framework of Rifi
*(https://github.com/CyanolabFreiburg/rifi)*. Generated outputs from the same
organism with different treatments could be gene based compared. 
Trying to combine segments of the same gene from different conditions is not 
straight forward and makes the data analysis nearly impossible. Therefore we 
developed a new workflow, rifi comparative data, with an easy strategy to make 
2 conditions comparable. 
The principle of rifi comparative data consists on segmenting the half-life 
(difference between half-life(condition1) and half-life(condition2) 
at probe/bin level) and segmenting intensity using the log2FC(mRNA at time 0). 
The workflow does not apply any hierarchy. Half-life (later HL) and intensity 
segmentation are independent.  
The fragments result of clustering from HL and intensity are compared at
log2FC(log2FC(half-life)/log2FC(intensity)). These values are a pre-analysis for
transcription and post-transcription regulation. Events for each treatment are 
depicted with the position on the genome (For more detail, refer to section xxx).
P-value from statistical tests are estimated. The comparison provides dataframe,
genome plot, scatter plot, heatmaps, histograms and density plot.


## II. Workflow

### 1. Joining data

The first step is combining the data from two conditions. The data are combined
by row on one hand and combined by column on the other hand. Both objects are 
saved and used as input for the next analysis.

The functions used are:

`combining_cdts_part_1`: you need to set the path for rifi statistics output from
each condition on one side and set the path for home directory where all objects
will be saved on other side. The "cdt" is added referring to the sample 
condition. 

<span style="color:red"> Very important: </span> you will need to run the 
differential expression at probe/bin level. This is the log2FC(intensity) or 
log2FC(mRNA at time 0). Pick-up the logFC, the p_value adjusted, probe position 
and strand columns. Save the first two as 'logFC_int' and 'P.Value'. 
You can use either `left_join` or `right_join` from dplyr package to join 
both data by strand and position. 

`combining_cdts_part_2`: contains `joining_data_row` function. It gathers 
dataframe from both conditions in one by rows. The object is called 
data_combined_se.rda

`combining_cdts_part_3`: contains `joining_data_column` function. It gathers 
dataframe from both conditions in one by columns. The object is called 
df_comb_se.rda

### 2. Penalties

Same as rifi workflow, to get the best segmentation we need the optimal penalties. 
To calculate HL penalty, the difference between half-life from both conditions
is calculated and added as distance_HL column. However the logFC_int is used to 
assign penalties for intensity values and named distance_int. 
`make_pen` function is applied in both cases.

The functions needed for penalty are:

`make_pen` calls one of two available penalty functions to automatically assign
penalties for the dynamic programming. Four functions are called:

 * `make_pen`
 * `fragment_HL_pen`
 * `fragment_inty_pen`
 * `score_fun_ave`

#### 1. `make_pen`

`make_pen` calls one of two available penalty functions to automatically
assign penalties for the dynamic programming. the function iterates over many
penalty pairs and picks the most suitable pair based on the difference between
wrong and correct splits. The sample size, penalty range and resolution as well
as the number of cycles can be customized. The primary start parameters create 
a matrix with n = rez_pen rows and n = rez_pen_out columns with values between
sta_pen/sta_pen_out and end_pen/end_pen_out. The best penalty pair is
picked. If dept is bigger than 1 the same process is repeated with a new matrix
of the same size based on the result of the previous cycle. Only position
segments with length within the sample size range are considered for the
penalties to increase run time. Also, outlier penalties cannot be smaller
than 40% of the respective penalty. For more detail check vignette from rifi
package.
<br/><br/>

#### 2. `fragment_HL_pen`

`fragment_HL_pen` is called by `make_pen` function to automatically assign
penalties for the dynamic programming of half-life fragments. The function used 
for `fragment_HL_pen` is `score_fun_ave`. `score_fun_ave` scores the values of 
y on how close they are to the mean. for more details, see below.

``` {r make_pen, eval = TRUE}
data(df_comb_minimal)

df_comb_minimal$distance_HL <-
    df_comb_minimal[, "half_life.cdt1"] - df_comb_minimal[, "half_life.cdt2"]

pen_HL <- make_pen(
    probe = df_comb_minimal,
    FUN = fragment_HL_pen,
    cores = 2,
    logs = as.numeric(rep(NA, 8)),
    dpt = 1,
    smpl_min = 10,
    smpl_max = 50,
    sta_pen = 0.5,
    end_pen = 4.5,
    rez_pen = 9,
    sta_pen_out = 0.5,
    end_pen_out = 3.5,
    rez_pen_out = 7
)
```
<br/><br/>

#### 3. `fragment_inty_pen`

`fragment_inty_pen` is called by `make_pen` function to automatically assign
penalties for the dynamic programming of intensity fragments. The function used for
`fragment_inty_pen` is `score_fun_ave`. 

#``` {r make_pen, eval = TRUE}
# df_comb_minimal$distance_int <- df_comb_minimal$logFC_int
# 
# pen_int <- make_pen(
#     probe = df_comb_minimal,
#     FUN = fragment_inty_pen,
#     cores = 60,
#     logs = as.numeric(rep(NA, 8)),
#     dpt = 1,
#     smpl_min = 10,
#     smpl_max = 50,
#     sta_pen = 0.5,
#     end_pen = 4.5,
#     rez_pen = 9,
#     sta_pen_out = 0.5,
#     end_pen_out = 3.5,
#     rez_pen_out = 7
# )
#```
<br/><br/>

#### 4. `score_fun_ave`

`score_fun_ave` scores the values of y on how close they are to the mean. 
for more details, see below.
<br/><br/>

### 3. Fragmentation

After finding the optimal set of penalties, fragmentation process could be applied.
The functions used are:
 
 `fragment_HL`
 `fragment_inty`
 `score_fun_ave`

#### 1. `fragment_HL`

`fragment_HL` performs the half_life fragmentation and assigns all gathered 
information to the probe based data frame. The columns "HL_comb_fragment" and 
"HL_mean_comb_fragment" are added to dataframe. `fragment_HL` makes 
half-life_fragments and assigns the mean of each fragment.

``` {r fragment_HL, eval = F}
df_comb_minimal <-
    fragment_HL(
    probe = df_comb_minimal,
    cores = 2,
    pen = pen_HL[[1]][[9]],
    pen_out = pen_HL[[1]][[10]]
)
```
<br/><br/>

#### 2. `fragment_inty`

`fragment_inty` performs the intensity fragmentation and assigns all gathered
information to the probe based data frame. The columns "intensity_comb_fragment"
and "intensity_mean_comb_ fragment" are added to the dataframe. `fragment_inty` 
makes intensity_fragments and assigns the mean of each fragment.
The hierarchy is not followed, fragments from different size could be generated 
independently of half-life fragments.

``` {r fragment_inty, eval = F}
df_comb_minimal <-
    fragment_inty(
    probe = df_comb_minimal,
    cores = 2,
    pen = pen_int[[1]][[9]],
    pen_out = pen_int[[1]][[10]]
)
```
<br/><br/>

#### 3. `score_fun_ave`

`score_fun_ave` is the score function used by dynamic programming for intensity
fragmentation, for more details, see below.


### 4. Statistics

To check segment significance, t-test with two.sided was used. Each fragment was
tested for the number of probes involved in each condition.

``` {r t_test_function, eval = F}
df_comb_minimal <-
    t_test_function(
        data = df_comb_minimal,
        par = "HL",
        par1 = "half_life",
        cdt1 = "sc",
        cdt2 = "fe",
        frag = frag_HL
    )
```


### 5. Visualization

The visualization depicts half-life and intensity slots of the fragments result 
of the dynamic programming. Since hierarchy is not applied, the fragments from 
half-life and intensity are independent.

``` {r rifi_visualization_comparison, eval = TRUE}
# rifi_visualization_comparison(
#     data = data_combined_minimal, 
#     data_c = df_comb_minimal,
#     genomeLength = annot_g[[2]],
#     annot = annot_g[[1]]
# )
```

Three objects are required:

 data_combined_minimal : data frame from joined data by row.
 df_comb_minimal : data frame from joined data by column
 annot : ggf3 preprocessed (for more information, see below)

## III. Outputs

### 1. The output Data Frame
**df_cdt** is the output data frame processed by **cdts_comparison** and 
**functions_cdts_comparison** functions. 
The **cdts_comparison** requires combined dataframe output from rifi_stats from 
both treatments. A new column is added to assign treatment type by 
**assembling_cdts** function. Both dataframes are merged by row. gff file is 
required to adapt the annotation. gff file is modified by **gff_preprocessing** 
function and saved as annot_g_c list object.

The data frame mainly contains:
<br/>
**cdt1** = condition 1
<br/>
**cdt2** = condition 2
<br/>
P.S: all annotations are gene based.
<br/>

**locus_tag** annotation object

**gene**  annotation object

**feature** region on the genome, from annotation object

**strand** annotation object

**delay_frg_cdt1** delay fragment

**delay_frg_cdt2** delay fragment

**HL_frg_cdt1** half-life fragments

**HL_frg_cdt2** half-life fragments

**HL_cdt1** mean of half-lives segment based (HL of segments covering the gene)

**HL_cdt2** mean of half-lives segment based (HL of segments covering the gene)

**HL_mean_cdt1** mean of means of half-lives probe based (HL of probes covering the gene)

**HL_mean_cdt2** mean of means of half-lives probe based (HL of probes covering the gene)

**log2FC_HL** half-life log2FC on non-treated/treated 

**int_frg_cdt1** intensity fragments

**int_frg_cdt2** intensity fragments

**int_cdt1** means of intensity

**int_cdt2** means of intensity

**int_mean_cdt1** mean of means of intensity

**int_mean_cdt1** mean of means of intensity

**log2FC_int** intensity log2FC on non-treated/treated

**log2FC_HL_int** log2FC half_life/intensity

**paus_cdt1** pausing sites positions 

**paus_cdt2** pausing sites positions 

**iTSS_I_cdt1** positions of internal starting sites predicted by delay fragments

**iTSS_I_cdt2** positions of internal starting sites predicted by delay fragments

**start** gene start on the genome

**end** gene end on the genome

**iTSS_II_cdt1** positions of internal starting sites predicted by HL and intensity fragments

**iTSS_II_cdt2** positions of internal starting sites predicted by HL and intensity fragments

**ter_cdt1** positions of terminales predicted by HL and intensity fragments

**ter_cdt2** positions of terminales predicted by HL and intensity fragments

**P.Value_HL** statistical test p_value of fold change HL fragments 

**adj.P.Val_HL** p_value adjusted of fold change HL fragments

**P.Value_int** statistical test p_value of fold change intensity fragments 

**adj.P.Val_int** p_value adjusted of fold change intensity fragments 

<br/><br/>
``` {r echo = TRUE}
load("head_df_cdt.rda")
Table_1 <- df[,-c(ncol(df) - 1, ncol(df) - 2, ncol(df) - 3)]
df
```
<br/><br/>
<p align="center">
**Figure 1**: dataframe.
</p>


<br/><br/>
``` {r log2FC, echo = FALSE, fig.cap = "**log2FC(HL/Intensity)**", out.width = '100%'}
knitr::include_graphics("Log2FC_HL_vs_int.png")
```
<br/>
<p align="center">
**Figure 2**: log2FC
</p>

<br/><br/>
``` {r density, echo = FALSE, fig.cap = "**HL density**", out.width = '100%'}
knitr::include_graphics("density_HL.pdf")
```
<br/>
<p align="center">
**Figure 3**: density
</p>


<br/><br/>
``` {r visualization, echo = FALSE, fig.cap = "**genome fragments superposed visualization**", out.width = '100%'}
knitr::include_graphics("visualization_cdts.png")
```
<br/>
<p align="center">
**Figure 4**: density
</p>


## III. Additional functions

### 1. `score_fun_ave`

`score_fun_ave` scores the difference of the values from their mean.
`score_fun_ave` calculates the mean of a minimum 2 values **y** and substrates
the difference from their mean. The IDs **z** and the sum of differences from
the mean are stored. A new value y is added, the mean is calculated and the new
IDs and sum of differences are stored. After several rounds, the minimum score
and the corresponding IDs is selected and stored as the best fragment.
`score_fun_ave` selects simultaneously for outliers, the maximum number is fixed
previously. Outliers are those values with high difference from the mean, they
are stored but excluded from the next calculation. The output of the function is
a vector of IDs separated by ",", a vector of mean separated by "_" and a
vector of outliers separated by ",".

### 2. `gff3_preprocess`

`gff3_preprocess` processes gff3 file from database, extracting gene names and
locus_tag from all coding regions (CDS). Other features like UTRs, ncRNA, asRNA
ect.. if available and the genome length are extracted. The output is a list of 2 elements.

The output data frame from `gff3_preprocess` function contains the following
columns:

a. *region*: CDS or any other available like UTRs, ncRNA, asRNA
b. *start*: start position of the gene
c. *end*: end position of the gene
d. *strand*: +/-
e. *gene*: gene annotation if available otherwise locus_tag annotation replaces
it
f. *locus_tag*: locus_tag annotation
<br/><br/>
``` {r gff3_preprocess}
# gff3_preprocess(path = gzfile(system.file(
#   "extdata", "gff_e_coli.gff3.gz", package = "rifi"
# )))
# gff3_preprocess(path = gzfile(
#   system.file("extdata", "gff_synechocystis_6803.gff.gz",
#               package = "rifi")
# ))
```
<br/><br/>

``` {r}
sessionInfo()
```